# -*- coding: utf-8 -*-
"""itechnolabs_submit.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vqhEUALDyy3OSYxjDEF2mo2gnr1wXCrP

# Problem Statement: Prediction of Diabetes using Machine Learning Algorithm

# Understanding data from CSV file

Data obtained from different csv files are in the form of train and test of 2 files each and it contains different features in the both of the files. So the two files merged together with total 70000 rows. In 'Age' column some of the rows are showing the age in the form of days and it is converted into years by calculations in csv file itself and then csv file was imported for data preprocessing

**Importing necessary dependencies**
"""

#importing libraries
import warnings
warnings.filterwarnings('ignore')
import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt
import seaborn as sns

"""# Data Cleaning & Exploratory Data Analysis consists of following steps

1)Data Preprocessing

2)Data Visualization

3)Handling Missing Values 

4)Feature Engineering

5)Handling Imbalanced Data

6)Outlier Treatment

7)Feature Selection

8)Feature Scaling

**1)Data Preprocessing**
"""

#import dataset
df = pd.read_csv('/content/drive/MyDrive/technolabs_assi/diabetes.csv')
df.head()

#Transformed column from days to years to be considered as age1 so removed age
df1 = df.drop('age',axis=1)
df1

df1.shape

#Handling Duplicates
df1.drop_duplicates()

df1.shape
#There are not duplicate values in dataset

df1.describe()

"""**Checking for Measures of Dispersion**

"""

df1.std()
# Here std dev value for 'weight' is indicating that data is spread widely from it's mean

df1.var()

df1.skew()
# Values of skewness for all the features are != 0 so the data is not normally distributed

df1.kurt()

#Checking for Null values
df1.isnull().sum()
#Weight column consits of 2318 missing values.

# unique values in diabetes coloumn. 1 corresponds to positive case and 0 to negative.
print(df1.diabetes.unique())

df1.info()

#We will first of all check all the missing value Percentage for each of the column
features_with_na = [features for features in df1.columns if df1[features].isnull().sum()>1]
# Print the % of missing values in each feature
for feature in features_with_na:
    print(feature, np.round(df1[feature].isnull().mean(),4),'%missing values')

"""**Data Visualization**

a) Univariate Analysis
"""

df2 = df1.drop(['cholesterol','gluc','pressure','gender'],axis=1)
df2

#Plotting the boxplot & Histplot, Boxplot gives the idea of outliers in terms of visualization plot
for i in df2.columns:
    plt.figure()
    plt.tight_layout()
    sns.set(rc={"figure.figsize":(8, 5)})
    f, (ax_box, ax_hist) = plt.subplots(2, sharex=True)
    plt.gca().set(xlabel= i,ylabel='Frequency')
    sns.boxplot(df2[i], ax=ax_box , linewidth= 1.0)
    sns.histplot(df2[i], ax=ax_hist , bins = 10,kde=True)
    plt.show()

"""**Boxplots for weight, height are showing more outliers**"""

#Plotting the violinplot
for i in df2.columns:
    plt.figure()
    plt.tight_layout()
    sns.set(rc={"figure.figsize":(8, 5)})
    f, (ax_vio, ax_hist) = plt.subplots(2, sharex=True)
    plt.gca().set(xlabel= i,ylabel='Frequency')
    sns.violinplot(df2[i], ax=ax_vio , linewidth= 1.0)
    sns.histplot(df2[i], ax=ax_hist , bins = 10,kde=True)

#Violin plots allow for quickly approximating where the data is centered and how it is spread.

"""**Violin plots are a great way of visualizing multimodal data. In smoke, alco there is bimodal distribution which is clearly observed in violin plot with the help of Probability Density Function**"""

#Checking the data whether balanced or imbalanced
# diabetes countplot
sns.countplot(x = 'diabetes',data = df2)
# diabetes = 1, no_diabetes = 0
# Following countplot indicates that the data consists of the people with diabetes is less than 30% as compared to no_diabetes. So our data is imbalanced data

"""**Bivariate Analysis**"""

# Scatter plot matrix 
from pandas.plotting import scatter_matrix
import pandas.plotting
scatter_matrix(df1, figsize = (20, 20));
# From Scatter plot is clearly indicating that the numeric variables are not correlated and does not possess any pattern in visualization

# Pairplot 
sns.pairplot(data = df2, hue = 'diabetes')
plt.show()
#Pairplot visualizes given data to find the relationship between them where the variables can be continuous or categorical.

"""**3)Handling Missing Values**

In dataset, only weight column consist of missing values so it needs to be handled because the missing data will decrease the predictive power of your model. If you apply algorithms with missing data, then there will be bias in the estimation of parameters. You cannot be confident about your results if you don’t handle missing data.
"""

df2['weight'] = df2['weight'].fillna(df2['weight'].median())
df2
# For this column I am using the median imputation instead of mean beacause it contains the outliers and mean is greatly affected by outliers

"""**4)Feature Engineering**

**Label Encoding for categorical features in the dataset such as cholesterol,gender,glucose, pressure**
"""

df_numeric = df2[['id', 'smoke', 'alco', 'active', 'age1', 'height','weight','diabetes']]
df_categorical = df1[['cholesterol', 'gluc', 'pressure', 'gender' ]]

df_categorical.head()

df1.columns

"""**Reason for using Label Encoding** : One-Hot Encoding results in a Dummy Variable Trap as the outcome of one variable can easily be predicted with the help of the remaining variables.The Dummy Variable Trap leads to the problem known as multicollinearity. Multicollinearity occurs where there is a dependency between the independent features. Multicollinearity is a serious issue in machine learning models like Linear Regression and Logistic Regression. So that I used the label encoding for categorical variables are available in dataset"""

from sklearn.preprocessing import LabelEncoder
diabetes_encoder = LabelEncoder()

le = LabelEncoder()

# apply "le.fit_transform"
df_encoded = df_categorical.apply(le.fit_transform)
print(df_encoded)

#Combining the encoded and numeric dataframe together
data = pd.concat([df_numeric,df_encoded],axis=1)
data

data.columns

data.isnull().sum()
# No missing values remainig in the dataset

"""**5)Handling Imbalanced Data**"""

#Checking the data whether balanced or imbalanced
# diabetes countplot
sns.countplot(x = 'diabetes',data = df2)
# diabetes = 1, no_diabetes = 0
# Following countplot indicates that the data consists of the people with diabetes is less than 30% as compared to no_diabetes. So our data is imbalanced data

y = data['diabetes'].astype(int)
#Seperate object from input features
X = data.drop('diabetes',axis=1)

"""**As data consits of diabetes with positive = 1 is very less than diabetes with negative =0 in proportion. So the data is imbalanced which may create the problem of correct prediction of diabetes and which may give faulty prediction. So we need to perform oversampling to make data balanced.**"""

from imblearn.over_sampling import RandomOverSampler
ros = RandomOverSampler()
X_os, y_os = ros.fit_resample(X,y)
X_os.shape, y_os.shape

"""**6)Outlier Treatment**"""

!pip install feature-engine

"""**Reason for using Winsorization Technique for handling outliers:** It makes sense to winsorize data when we want to retain the observations that are at the extremes but we don't want to take them too literally"""

from feature_engine.outliers import Winsorizer
IQR = data.quantile(0.75) - data.quantile(0.25)
lower_limit = data.quantile(0.25) - (IQR * 1.5)
upper_limit = data.quantile(0.75) + (IQR * 1.5)

for i in data:
    winsor = Winsorizer(capping_method='iqr',
                            tail='both',
                            fold=1.5,
                            variables=[i])
    data[i] = winsor.fit_transform(data[[i]])

import seaborn as sns
for feature in data:
    sns.boxplot(data[feature])
    plt.show()

"""**7)Feature Selection**

The sns.heatmap is used to visualize the features in the form of correlation coeffient. If two variables are highly correlated then we drop either of them from dataframe because it gives same effect on the target variable.
"""

#Pearson Correlation 
plt.figure(figsize=(10, 12))
cor = df2.corr()
sns.heatmap(cor,annot=True, cmap = plt.cm.CMRmap_r)
plt.show()

#with the follwing function we can select highly correlated features 
#it will remove the features that is correlated with anything other feature
def correlation(df2, threshold):
    col_corr = set()   #set of all the names of correlated columns
    corr_matrix = df2.corr()
    for i in range(len(corr_matrix.columns)):
        for j in range(i):
            if (corr_matrix.iloc[i,j]) > threshold: #we interested in absolute coefficient values 
                colname = corr_matrix.columns[i]   #getting the name of column
                col_corr.add(colname)
    return col_corr

corr_features = correlation(df2, 0.7)
len(set(corr_features))
# There are zero no. of features are highly correlated so we don't need tp drop the any of the feature from dataset

"""**Now data is cleaned for model building**

#Apply the Machine Learning Algorithm-Classification Algorithm
1)Logistic Regression

2)KNN

3)Naive Bayes

4)SVM

5)Decision Tree

6)Random F0rest

**8) Feature Scaling**

Before model building it necessary to scale the features for that matter standard scaler is used
"""

# Apply Standard Scaler
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X)
SSX = scaler.transform(X)

#Train Test Split

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(SSX, y, test_size=0.2, random_state = 7)

"""**1)Logistic Regression**"""

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(solver='liblinear',multi_class='ovr')
lr.fit(X_train, y_train)

lr_pred = lr.predict(X_test)
lr_pred

"""**2)KNearestneighbourClassifier(KNN)**"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()
knn.fit(X_train, y_train)

knn_pred = knn.predict(X_test)
knn_pred

"""**3)Naive-Bayes Classifier**"""

from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()
nb.fit(X_train, y_train)

nb_pred = nb.predict(X_test)
nb_pred

"""**4)Support Vector Machine**"""

from sklearn.svm import SVC
sv = SVC()
sv.fit(X_train, y_train)

svm_pred = sv.predict(X_test)
svm_pred

"""**5)DecisionTree**"""

from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)

dt_pred = dt.predict(X_test)
dt_pred

"""**6)Random Forest**"""

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier()
rf.fit(X_train, y_train)

rf_pred = rf.predict(X_test)
rf_pred

"""**Model Evaluation**

**Test & Test Score**
"""

# Train and Test Score for Logistic Regression
from sklearn.metrics import accuracy_score
print("Train Accuracy of Logistic Regression", lr.score(X_train, y_train)*100)
print("Accuracy (Test) score of Logistic Regression", lr.score(X_test, y_test)*100)
print("Accuacy (Test) score of Logistic Regression",accuracy_score(y_test, lr_pred)*100)

# Train and Test Score for KNN
print("Train Accuracy of KNN", knn.score(X_train, y_train)*100)
print("Accuracy (Test) score of KNN", knn.score(X_test, y_test)*100)
print("Accuacy (Test) score of KNN",accuracy_score(y_test, knn_pred)*100)

# Train and Test Score for NB
print("Train Accuracy of NB", nb.score(X_train, y_train)*100)
print("Accuracy (Test) score of NB", nb.score(X_test, y_test)*100)
print("Accuacy (Test) score of NB",accuracy_score(y_test, nb_pred)*100)

# Train and Test Score for DT
print("Train Accuracy of DT", dt.score(X_train, y_train)*100)
print("Accuracy (Test) score of dt", dt.score(X_test, y_test)*100)
print("Accuacy (Test) score of dt",accuracy_score(y_test, dt_pred)*100)

# Train and Test Score for RF
print("Train Accuracy of RF", rf.score(X_train, y_train)*100)
print("Accuracy (Test) score of RF", rf.score(X_test, y_test)*100)
print("Accuacy (Test) score of RF",accuracy_score(y_test, rf_pred)*100)

# Train and Test Score for SVM
print("Train Accuracy of SVM", sv.score(X_train, y_train)*100)
print("Accuracy (Test) score of SVM", sv.score(X_test, y_test)*100)
print("Accuacy (Test) score of svm",accuracy_score(y_test, svm_pred)*100)

"""**Selecting the best algorithm on the basis of accuracy obtained from data it is correctly predicting 96%**

**Confusion Matrix**

**For SVM**
"""

from sklearn.metrics import classification_report,confusion_matrix
cm = confusion_matrix(y_test, svm_pred)
sns.heatmap(confusion_matrix(y_test, svm_pred),annot=True, fmt = "d")

"""**Classification Report**"""

print('Classifiaction Report of Logistic Regression: \n',classification_report(y_test,svm_pred,digits=4))

"""**Conclusion from Classification Report**

**1)Precision-Model identifies the diabetes is positive = 1 and  it is correct 94.42% of the time.**

**2)Precision-Model identifies the diabetes is negative = 0 and  it is correct 96.53% of the time.**

**3)Our model has a recall of 0.9737—in other words, it correctly identifies 97.37% of all negative diabetes patients**

**4)Our model has a recall of 0.9192—in other words, it correctly identifies 91.92 % of all positive diabetes patients**
"""

#Area under Curve
from sklearn.metrics import accuracy_score,roc_auc_score, roc_curve
auc = roc_auc_score(y_test,svm_pred)
fpr, tpr , thresholds = roc_curve(y_test, svm_pred)
plt.plot(fpr, tpr, color='orange', label = 'ROC')
plt.plot([0,1],[0,1], color = 'darkblue',linestyle = '--', label='ROC curve (area = %0.2f)' %auc)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characterstics Curve of SVM')
plt.legend()
plt.grid()
plt.show()

"""**Prediction for New Dataset**"""

X_train[0].reshape(1,-1)

#Transformation of New Data
scaler.transform(X_train[0].reshape(1,-1))

sv.predict(scaler.transform(X_train[0].reshape(1,-1)))

"""**Pickling The Model For Deployment**"""

import pickle
pickle.dump(sv, open('svmclassifier.pkl','wb'))
pickled_model = pickle.load(open('svmclassifier.pkl','rb'))

#Prediction
pickled_model.predict(scaler.transform(X_train[0].reshape(1,-1)))

"""**Out of 6 Classification algorithm SVM has given the good accuracy than others so SVM is used to build the ML model for predicting Diabetes of Patient**

#Hyperparameter Optimization by Using GridSearchCV
"""

from sklearn.tree import DecisionTreeClassifier
tree=DecisionTreeClassifier()

#Using GridSearchCV
from sklearn.model_selection import GridSearchCV
params_dict={'criterion':["gini", "entropy"],'splitter':["best", "random"],'max_depth':[1,2,3,4],'min_samples_split':[1,2,3],'min_samples_leaf':[1,2],'max_features':["auto", "sqrt", "log2"]}
scv=GridSearchCV(tree,params_dict,cv=10)
scv.fit(X_train,y_train)

scv.best_params_

#Using DecisionTreeClassifier and fitting the data with above suggested parameters
tree=DecisionTreeClassifier(criterion= 'gini',max_depth= 3,max_features='sqrt',min_samples_leaf= 1,min_samples_split= 2,
splitter= 'random')
tree.fit(X_train,y_train)

tree.score(X_test,y_test)

y_pred=tree.predict(X_test)

plt.scatter(y_test,y_pred)
plt.show()

"""**Hyperparameter Optimization using RandomizedSearchCV using XGBoost**"""

## Hyper Parameter Optimization

params={
 "learning_rate"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,
 "max_depth"        : [ 3, 4, 5, 6, 8, 10, 12, 15],
 "min_child_weight" : [ 1, 3, 5, 7 ],
 "gamma"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],
 "colsample_bytree" : [ 0.3, 0.4, 0.5 , 0.7 ]
    
}

## Hyperparameter optimization using RandomizedSearchCV
from sklearn.model_selection import RandomizedSearchCV
import xgboost

classifier=xgboost.XGBClassifier()

random_search=RandomizedSearchCV(classifier,param_distributions=params,n_iter=5,scoring='roc_auc',n_jobs=-1,cv=5,verbose=3)
random_search

from datetime import datetime
def timer(start_time=None):
    if not start_time:
        start_time = datetime.now()
        return start_time
    elif start_time:
        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)
        tmin, tsec = divmod(temp_sec, 60)
        print('\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))

# Here we go
start_time = timer(None) # timing starts from this point for "start_time" variable
random_search.fit(X_train,y_train.ravel())
timer(start_time) # timing ends here for "start_time" variable

random_search.best_estimator_

classifier = xgboost.XGBClassifier(colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=6, min_child_weight=3)

classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)

cm_h = confusion_matrix(y_test, y_pred)
score = accuracy_score(y_test, y_pred)
print(cm_h)
print(score)

from sklearn.model_selection import cross_val_score
score = cross_val_score(classifier,X_train, y_train.ravel(),cv=10)
score

score.mean()

"""**After Hyperparameter Optimization using GridSearchCV  the accuracy score is improved to 0.9726 and best_estimator is found to XGBClassifier because in hyperparameter Optimization using DT the accuracy got dropped**"""

